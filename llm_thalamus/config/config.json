{
  "embeddings": {
    "model": "nomic-embed-text",
    "ollama_url": "http://localhost:11434",
    "provider": "ollama"
  },
  "logging": {
    "file": "./log/thalamus.log",
    "level": "INFO",
    "thalamus_enabled": false,
    "ui_chat_session_enabled": false
  },
  "openmemory": {
    "mode": "local",
    "path": "./data/memory.sqlite",
    "tier": "smart"
  },
  "thalamus": {
    "message_history": 100,
    "message_file": "chat_history.jsonl",
    "calls": {
      "answer": {
        "flags": {
          "show_memory_annotations": true
        },
        "max_memories": 1,
        "max_messages": 13,
        "memory_limits_by_sector": {
          "emotional": 3,
          "episodic": 3,
          "procedural": 5,
          "reflective": 7,
          "semantic": 5
        },
        "prompt_file": "config/prompt_answer.txt",
        "use_documents": true,
        "use_history": true,
        "use_memories": true
      },
      "execute": {
        "flags": {},
        "max_memories": null,
        "max_messages": null,
        "prompt_file": null,
        "use_documents": true,
        "use_history": true,
        "use_memories": true
      },
      "plan": {
        "flags": {},
        "max_memories": null,
        "max_messages": null,
        "prompt_file": null,
        "use_documents": true,
        "use_history": true,
        "use_memories": true
      },
      "reflection": {
        "flags": {},
        "max_memories": null,
        "max_messages": 5,
        "memory_limits_by_sector": {
          "emotional": 1,
          "episodic": 4,
          "procedural": 3,
          "reflective": 5,
          "semantic": 4
        },
        "prompt_file": "config/prompt_reflection.txt",
        "use_documents": false,
        "use_history": true,
        "use_memories": true
      },
      "space_answer": {
        "flags": {},
        "max_memories": null,
        "max_messages": null,
        "prompt_file": null,
        "use_documents": true,
        "use_history": true,
        "use_memories": true
      },
      "space_reflection": {
        "flags": {},
        "max_memories": null,
        "max_messages": null,
        "prompt_file": null,
        "use_documents": true,
        "use_history": true,
        "use_memories": true
      },
      "understand": {
        "flags": {},
        "max_memories": null,
        "max_messages": null,
        "prompt_file": null,
        "use_documents": true,
        "use_history": true,
        "use_memories": true
      }
    },
    "default_user_id": "default",
    "enable_reflection": true,
    "llm_model": "qwen2.5:7b",
    "max_memory_results": 40,
    "max_tool_steps": 16,
    "project_name": "llm-thalamus",
    "short_term_memory": {
      "max_messages": 7
    }
  },
  "tools": {
    "memory.retrieve": {
      "args_schema": {
        "k": "integer (optional) – max number of memories to retrieve",
        "query": "string (required) – natural language query"
      },
      "description": "Retrieve relevant memories from the long-term store.",
      "kind": "internal_memory",
      "returns": {
        "k": "integer or null – requested k, if provided",
        "memories": "string – a text block with relevant memories (may be empty)",
        "ok": "boolean – success flag",
        "query": "string – the query that was used"
      }
    }
  },
  "ui": {
    "auto_connect_thalamus": true,
    "show_previous_session_on_startup": true,
    "thalamus_log": {
      "filter_mode": "denylist",
      "labels": {
        "debug": false,
        "llm_answer": false,
        "llm_reflect_raw": false,
        "memory": false,
        "open_documents_effective": false,
        "open_documents_raw": false,
        "pipeline": false,
        "reflection": false,
        "retrieval_plan": false,
        "session": false,
        "status": false
      }
    }
  },
  "ui_descriptions": {
    "logging.thalamus_enabled": "Enable thalamus logging (per-session log files)"
  }
}